# üóÑÔ∏è Estrat√©gias para Bancos de Dados Grandes

## Quando o Banco Excede os Limites Gratuitos

### Op√ß√£o 1: Otimiza√ß√£o e Limpeza (Recomendado Primeiro)

**Scripts de Limpeza:**
```sql
-- Remover dados antigos (manter √∫ltimos 6 meses)
DELETE FROM sales WHERE created_at < NOW() - INTERVAL '6 months';

-- Arquivar dados hist√≥ricos em tabelas separadas
CREATE TABLE sales_archive AS SELECT * FROM sales WHERE created_at < NOW() - INTERVAL '1 year';
DELETE FROM sales WHERE created_at < NOW() - INTERVAL '1 year';

-- Limpar tabelas tempor√°rias
TRUNCATE TABLE temp_data;

-- Vacuum para recuperar espa√ßo
VACUUM FULL;
```

**Otimiza√ß√£o de Estrutura:**
```sql
-- Adicionar √≠ndices para queries frequentes
CREATE INDEX CONCURRENTLY idx_sales_brand_date ON sales(brand_id, created_at DESC);
CREATE INDEX CONCURRENTLY idx_sales_channel ON sales(channel_id);
CREATE INDEX CONCURRENTLY idx_products_category ON products(category_id);

-- Particionamento por data (para tabelas muito grandes)
CREATE TABLE sales_y2024 PARTITION OF sales FOR VALUES FROM ('2024-01-01') TO ('2025-01-01');
```

#### Op√ß√£o 2: Estrat√©gia de Dados em Camadas

**Banco H√≠brido:**
- **Dados Quentes**: √öltimos 3-6 meses (banco gratuito)
- **Dados Frios**: Hist√≥rico antigo (arquivo CSV/S3 gratuito)

```javascript
// Estrat√©gia de cache + archive
const getSalesData = async (brandId, months = 6) => {
  // Dados recentes do banco
  const recentData = await pool.query(`
    SELECT * FROM sales
    WHERE brand_id = $1 AND created_at >= NOW() - INTERVAL '${months} months'
  `, [brandId]);

  // Dados antigos do cache/S3 se necess√°rio
  if (months > 6) {
    const archivedData = await getArchivedData(brandId, months);
    return [...recentData.rows, ...archivedData];
  }

  return recentData.rows;
};
```

#### Op√ß√£o 3: Upgrade para Tier Pago Quando Necess√°rio

**Supabase Pago (a partir de $25/m√™s):**
- ‚úÖ At√© 100GB storage
- ‚úÖ Backup autom√°tico
- ‚úÖ Read replicas

**Railway Pago (a partir de $5/m√™s):**
- ‚úÖ At√© 8GB RAM
- ‚úÖ At√© 100GB storage
- ‚úÖ CPU dedicada

**Neon Pago (a partir de $19/m√™s):**
- ‚úÖ At√© 1TB storage
- ‚úÖ Computa√ß√£o dedicada
- ‚úÖ Backup autom√°tico

### Monitoramento de Uso

**Queries para Verificar Tamanho:**
```sql
-- Tamanho total do banco
SELECT pg_size_pretty(pg_database_size(current_database()));

-- Tamanho por tabela
SELECT schemaname, tablename, pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size
FROM pg_tables
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;

-- Rows por tabela
SELECT schemaname, tablename, n_tup_ins - n_tup_del as rowcount
FROM pg_stat_user_tables
ORDER BY n_tup_ins - n_tup_del DESC;
```

### Estrat√©gia de Migra√ß√£o

**Passos para Migrar Banco Grande:**

1. **Backup Completo:**
   ```bash
   pg_dump $DATABASE_URL > backup.sql
   ```

2. **Limpeza de Dados:**
   ```sql
   -- Script de limpeza antes da migra√ß√£o
   DELETE FROM audit_logs WHERE created_at < NOW() - INTERVAL '1 year';
   DELETE FROM temp_sessions WHERE expires_at < NOW();
   ```

3. **Migra√ß√£o para Servi√ßo Pago:**
   - Criar novo banco no servi√ßo pago
   - Restaurar backup limpo
   - Atualizar connection string
   - Testar aplica√ß√£o

4. **Otimiza√ß√£o P√≥s-Migra√ß√£o:**
   ```sql
   -- Reindexar tudo
   REINDEX DATABASE current_database;

   -- Vacuum full
   VACUUM FULL;

   -- Analyze para estat√≠sticas
   ANALYZE;
   ```

### Alternativas para Dados Muito Grandes

#### 1. ClickHouse (para Analytics)
- **Gratuito**: Community edition
- **Vantagem**: Compress√£o extrema, queries anal√≠ticas r√°pidas
- **Uso**: Migrar dados hist√≥ricos para ClickHouse

#### 2. BigQuery (Google)
- **Gratuito**: 1TB queries/m√™s, 10GB storage
- **Vantagem**: Serverless, integra√ß√£o com Google Cloud

#### 3. Estrat√©gia Multi-Banco
```
Aplica√ß√£o ‚Üí PostgreSQL (dados recentes) + ClickHouse (hist√≥rico)
```

### Checklist para Banco Grande

- [ ] Verificar tamanho atual: `SELECT pg_size_pretty(pg_database_size(current_database()));`
- [ ] Identificar tabelas grandes
- [ ] Avaliar dados necess√°rios vs hist√≥ricos
- [ ] Implementar limpeza autom√°tica
- [ ] Configurar monitoramento de crescimento
- [ ] Planejar upgrade quando aproximar limite

### Recomenda√ß√£o por Tamanho

- **< 100MB**: Qualquer op√ß√£o gratuita
- **100MB - 500MB**: Supabase gratuito, Railway gratuito
- **500MB - 2GB**: Railway pago ($5/m√™s), Supabase pago ($25/m√™s)
- **> 2GB**: Neon pago ($19/m√™s), AWS RDS, Google Cloud SQL

### Scripts de Manuten√ß√£o Autom√°tica

**Fun√ß√£o para Limpeza Autom√°tica:**
```sql
CREATE OR REPLACE FUNCTION cleanup_old_data() RETURNS void AS $$
BEGIN
    -- Deletar vendas antigas (manter 1 ano)
    DELETE FROM sales WHERE created_at < NOW() - INTERVAL '1 year';

    -- Deletar logs antigos (manter 6 meses)
    DELETE FROM audit_logs WHERE created_at < NOW() - INTERVAL '6 months';

    -- Limpar cache antigo
    DELETE FROM cache WHERE expires_at < NOW();

    -- Vacuum para liberar espa√ßo
    VACUUM;
END;
$$ LANGUAGE plpgsql;

-- Executar limpeza mensal
SELECT cron.schedule('cleanup-old-data', '0 2 1 * *', 'SELECT cleanup_old_data();');
```

**Dica**: Comece otimizando e limpando dados antes de migrar para servi√ßos pagos!
